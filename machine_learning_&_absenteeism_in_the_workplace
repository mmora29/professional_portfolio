# Advanced Regressions

import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as scipy
from numpy import mean
from numpy import std

#classification models
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn import linear_model
#Import scikit-learn metrics module for accuracy calculations
from sklearn import metrics
#Import train_test_split function
from sklearn.model_selection import train_test_split
from matplotlib import pyplot
from scipy.stats import gaussian_kde
from scipy.stats import pearsonr
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from math import sqrt



os.getcwd()
absent = pd.read_csv("Absenteeism_at_work_cleansed.csv")
absent.head()

absent.shape
# (740,21)

# To Check Null Values
absent.isnull().sum()
# No Nulls

# Get Statistics from the data.
absent.describe()

corr = absent.corr()
print(corr)

# Check the skewness value. This should be between -1 and +1. Any deviation from this indicates extrem values
print(absent.skew())

# Create a heatmap
sns.heatmap(corr, annot=True, linewidth = .1, cmap = 'coolwarm')
plt.show()

# Show the Absenteeism time in hours in box plot for outliers

plt.boxplot(absent['Absenteeism time in hours'])
plt.show()

# Outlier treatment (Quantile-Based Flooring & Capping) - Absenteeism time in hours

print(absent['Absenteeism time in hours'].quantile(0.10))
print(absent['Absenteeism time in hours'].quantile(0.90))

# Removing the outliers (Absenteeism time in hours)
absent["Absenteeism time in hours"] = np.where(absent["Absenteeism time in hours"] <1.0, 1.0,absent['Absenteeism time in hours'])
absent["Absenteeism time in hours"] = np.where(absent["Absenteeism time in hours"] >8.0, 8.0,absent['Absenteeism time in hours'])
print(absent["Absenteeism time in hours"].skew())

# Check the skewness value. This should be between -1 and +1. Any deviation from this indicates extrem values
print(absent.skew())


# Months of absence & Seasons Correlation Ration -  0.40
# Pet & Transportation Expense – 0.40
# Transportation Expense & Distance from residence to Work – 0.26
# Transportation Expense & Son – 0.38
# Weight & Social Drinking - 0.37
# Service TIme & Weight – 0.45
# Service Time & Body Mass Index – 0.49
# Body Mass index & Weight - 0.90

# Varibles to predict Absenteeism time in hours
x=absent[['Service time','Weight','Body mass index']]
x_labels=['Service time','Weight','Body mass index']
y=absent['Absenteeism time in hours']

# Initialize the linear regression model
reg = linear_model.LinearRegression()

# 70% training and 30% Test
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)

# Train the model with Training data
reg.fit(x_train, y_train)
print(x_train.shape);print(x_test.shape)

# Print the coefficients/weights for each feature/column of our model
print(reg.coef_)

# Print the predictions on the data
y_pred = reg.predict(x_test)
print(y_pred)

# Print the actual values
print(y_test)
# Checking the performance/Accuracy of the Model using MEAN SQUARE ERROR (MSE)
print(np.mean( (y_pred - y_test)**2))

# This number should be as close to Zero as possible.
# This model is very bad.

# Checking the performance/Accuracy of the Model using MEAN SQUARE ERROR (MSE)and sllearn.metrics

print(mean_squared_error(y_test,y_pred))
r_sq = reg.score(x_train, y_train)
print('coeffcient of determination:', r_sq)


################## Model 1 - Linear Regression #######################
from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(x_train, y_train)

# Define Model - Output
pred_train_lr= lr.predict(x_train)
print(np.sqrt(mean_squared_error(y_train,pred_train_lr)))
print(r2_score(y_train, pred_train_lr))


pred_test_lr= lr.predict(x_test)
print(np.sqrt(mean_squared_error(y_test,pred_test_lr)))
print(r2_score(y_test, pred_test_lr))
print('interceptor:', reg.intercept_)
print('slope:', reg.coef_)


############## Model 2 - Lasso #######################################

model_lasso = Lasso(alpha=0.01)
model_lasso.fit(x_train, y_train)
pred_train_lasso= model_lasso.predict(x_train)
print(np.sqrt(mean_squared_error(y_train,pred_train_lasso)))
print(r2_score(y_train, pred_train_lasso))

pred_test_lasso= model_lasso.predict(x_test)
print(np.sqrt(mean_squared_error(y_test,pred_test_lasso)))
print(r2_score(y_test, pred_test_lasso))


############# Model 3 - Decision Tree ##########################

dtree = DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)
dtree.fit(x_train, y_train)

# Model Performance on Test Data

pred_test_tree= dtree.predict(x_test)
print(np.sqrt(mean_squared_error(y_test,pred_test_tree)))
print(r2_score(y_test, pred_test_tree))

# Improve the model by tuning the parameters ('max depth of 2 & 5')

dtree1 = DecisionTreeRegressor(max_depth=2)
dtree2 = DecisionTreeRegressor(max_depth=5)
dtree1.fit(x_train, y_train)
dtree2.fit(x_train, y_train)

tr1 = dtree1.predict(x_train)
tr2 = dtree2.predict(x_train)

y1 = dtree1.predict(x_test)
y2 = dtree2.predict(x_test)


# Print RMSE and R-squared value for regression tree 'dtree1' on training data
print(np.sqrt(mean_squared_error(y_train,tr1)))
print(r2_score(y_train, tr1))

# Print RMSE and R-squared value for regression tree 'dtree1' on testing data
print(np.sqrt(mean_squared_error(y_test,y1)))
print(r2_score(y_test, y1))


# Print RMSE and R-squared value for regression tree 'dtree2' on training data
print(np.sqrt(mean_squared_error(y_train,tr2)))
print(r2_score(y_train, tr2))

# Print RMSE and R-squared value for regression tree 'dtree2' on testing data
print(np.sqrt(mean_squared_error(y_test,y2)))
print(r2_score(y_test, y2))

################################################### END ################################
